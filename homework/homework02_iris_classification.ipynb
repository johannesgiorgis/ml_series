{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 02: Iris Classification\n",
    "\n",
    "Homework 02 entails us improving the Iris classification models:\n",
    "\n",
    "**Ways to improve on the Iris models**\n",
    "\n",
    "1. Adjust hyperparameters of models\n",
    "2. Add features\n",
    "     - Try Length / Width\n",
    "     - Use Unsupervised model (K-Means)\n",
    "3. Add models to set\n",
    "    - XGBoost\n",
    "    - lightGBM\n",
    "4. Add Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\"\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "dataset = pd.read_csv(url, names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (150, 5) \n",
      "\n",
      "First records of data:\n",
      "    sepal-length  sepal-width  petal-length  petal-width        class\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4           5.0          3.6           1.4          0.2  Iris-setosa \n",
      "\n",
      "Class Distribution:\n",
      "class\n",
      "Iris-setosa        50\n",
      "Iris-versicolor    50\n",
      "Iris-virginica     50\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# shape\n",
    "print(\"Shape: \", dataset.shape, '\\n')\n",
    "\n",
    "# head\n",
    "print(\"First records of data:\\n\", dataset.head(), '\\n')\n",
    "\n",
    "# class distribution\n",
    "print('Class Distribution:')\n",
    "print(dataset.groupby('class').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical description of data:\n",
      "        sepal-length  sepal-width  petal-length  petal-width\n",
      "count    150.000000   150.000000    150.000000   150.000000\n",
      "mean       5.843333     3.054000      3.758667     1.198667\n",
      "std        0.828066     0.433594      1.764420     0.763161\n",
      "min        4.300000     2.000000      1.000000     0.100000\n",
      "25%        5.100000     2.800000      1.600000     0.300000\n",
      "50%        5.800000     3.000000      4.350000     1.300000\n",
      "75%        6.400000     3.300000      5.100000     1.800000\n",
      "max        7.900000     4.400000      6.900000     2.500000\n"
     ]
    }
   ],
   "source": [
    "print(\"Statistical description of data:\\n\",dataset.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dataset.values\n",
    "X = array[:,0:4]\n",
    "Y = array[:,4]\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(\n",
    "    X,\n",
    "    Y,\n",
    "    test_size=validation_size,\n",
    "    random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model Shells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LR',\n",
       "  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "            n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "            tol=0.0001, verbose=0, warm_start=False)),\n",
       " ('LDA',\n",
       "  LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "                solver='svd', store_covariance=False, tol=0.0001)),\n",
       " ('KNN',\n",
       "  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "             metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "             weights='uniform')),\n",
       " ('CART',\n",
       "  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "              splitter='best')),\n",
       " ('RF',\n",
       "  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False)),\n",
       " ('NB', GaussianNB(priors=None, var_smoothing=1e-09)),\n",
       " ('SVM', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spot test each model with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.9667 (0.0408)\n",
      "LDA: 0.9750 (0.0382)\n",
      "KNN: 0.9833 (0.0333)\n",
      "CART: 0.9667 (0.0408)\n",
      "RF: 0.9750 (0.0382)\n",
      "NB: 0.9750 (0.0534)\n",
      "SVM: 0.9917 (0.0250)\n"
     ]
    }
   ],
   "source": [
    "# Test options and evaluation metric\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "# evaluate each model in turn\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(\n",
    "        model, X_train, Y_train, cv=kfold, scoring=scoring\n",
    "    )\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = f\"{name}: {cv_results.mean():0.4f} ({cv_results.std():0.4f})\"\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions on validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(model):\n",
    "    print(model)\n",
    "    model.fit(X_train, Y_train)\n",
    "    predictions = model.predict(X_validation)\n",
    "\n",
    "    print(\"Accuracy Score:\", accuracy_score(Y_validation, predictions))\n",
    "    print(\"\\nConfusion Matrix:\\n\", confusion_matrix(Y_validation, predictions))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "Accuracy Score: 0.9\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 7  0  0]\n",
      " [ 0 11  1]\n",
      " [ 0  2  9]]\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         7\n",
      "Iris-versicolor       0.85      0.92      0.88        12\n",
      " Iris-virginica       0.90      0.82      0.86        11\n",
      "\n",
      "      micro avg       0.90      0.90      0.90        30\n",
      "      macro avg       0.92      0.91      0.91        30\n",
      "   weighted avg       0.90      0.90      0.90        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "make_prediction(KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "Accuracy Score: 0.8\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 7  0  0]\n",
      " [ 0  7  5]\n",
      " [ 0  1 10]]\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         7\n",
      "Iris-versicolor       0.88      0.58      0.70        12\n",
      " Iris-virginica       0.67      0.91      0.77        11\n",
      "\n",
      "      micro avg       0.80      0.80      0.80        30\n",
      "      macro avg       0.85      0.83      0.82        30\n",
      "   weighted avg       0.83      0.80      0.80        30\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LDA\n",
      "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
      "              solver='svd', store_covariance=False, tol=0.0001)\n",
      "Accuracy Score: 0.9666666666666667\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 7  0  0]\n",
      " [ 0 11  1]\n",
      " [ 0  0 11]]\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         7\n",
      "Iris-versicolor       1.00      0.92      0.96        12\n",
      " Iris-virginica       0.92      1.00      0.96        11\n",
      "\n",
      "      micro avg       0.97      0.97      0.97        30\n",
      "      macro avg       0.97      0.97      0.97        30\n",
      "   weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "KNN\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "Accuracy Score: 0.9\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 7  0  0]\n",
      " [ 0 11  1]\n",
      " [ 0  2  9]]\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         7\n",
      "Iris-versicolor       0.85      0.92      0.88        12\n",
      " Iris-virginica       0.90      0.82      0.86        11\n",
      "\n",
      "      micro avg       0.90      0.90      0.90        30\n",
      "      macro avg       0.92      0.91      0.91        30\n",
      "   weighted avg       0.90      0.90      0.90        30\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CART\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "Accuracy Score: 0.9\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 7  0  0]\n",
      " [ 0 10  2]\n",
      " [ 0  1 10]]\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         7\n",
      "Iris-versicolor       0.91      0.83      0.87        12\n",
      " Iris-virginica       0.83      0.91      0.87        11\n",
      "\n",
      "      micro avg       0.90      0.90      0.90        30\n",
      "      macro avg       0.91      0.91      0.91        30\n",
      "   weighted avg       0.90      0.90      0.90        30\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RF\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Accuracy Score: 0.8666666666666667\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 7  0  0]\n",
      " [ 0 10  2]\n",
      " [ 0  2  9]]\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         7\n",
      "Iris-versicolor       0.83      0.83      0.83        12\n",
      " Iris-virginica       0.82      0.82      0.82        11\n",
      "\n",
      "      micro avg       0.87      0.87      0.87        30\n",
      "      macro avg       0.88      0.88      0.88        30\n",
      "   weighted avg       0.87      0.87      0.87        30\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NB\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "Accuracy Score: 0.8333333333333334\n",
      "\n",
      "Confusion Matrix:\n",
      " [[7 0 0]\n",
      " [0 9 3]\n",
      " [0 2 9]]\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         7\n",
      "Iris-versicolor       0.82      0.75      0.78        12\n",
      " Iris-virginica       0.75      0.82      0.78        11\n",
      "\n",
      "      micro avg       0.83      0.83      0.83        30\n",
      "      macro avg       0.86      0.86      0.86        30\n",
      "   weighted avg       0.84      0.83      0.83        30\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SVM\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "Accuracy Score: 0.9333333333333333\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 7  0  0]\n",
      " [ 0 10  2]\n",
      " [ 0  0 11]]\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         7\n",
      "Iris-versicolor       1.00      0.83      0.91        12\n",
      " Iris-virginica       0.85      1.00      0.92        11\n",
      "\n",
      "      micro avg       0.93      0.93      0.93        30\n",
      "      macro avg       0.95      0.94      0.94        30\n",
      "   weighted avg       0.94      0.93      0.93        30\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    print(name)\n",
    "    make_prediction(model)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "# map the iris class to numerical values\n",
    "class_map = {\n",
    "    'Iris-setosa': 0,\n",
    "    'Iris-versicolor': 1,\n",
    "    'Iris-virginica': 2\n",
    "}\n",
    "Y_new = [class_map[iris_class] for iris_class in Y]\n",
    "\n",
    "# split data into train and validation sets\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(\n",
    "    X,\n",
    "    Y_new,\n",
    "    test_size=validation_size,\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "d_train = xgb.DMatrix(X_train, label=Y_train)\n",
    "d_validate = xgb.DMatrix(X_validation, label=Y_validation)\n",
    "\n",
    "# set xgboost params\n",
    "param = {\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.3,\n",
    "    'silent': 1,\n",
    "    'objective': 'multi:softprob',\n",
    "    'num_class': 3\n",
    "}\n",
    "num_round = 20\n",
    "\n",
    "# train model\n",
    "bst = xgb.train(param, d_train, num_round)\n",
    "\n",
    "# predict\n",
    "predictions = bst.predict(d_validate)\n",
    "\n",
    "# pick best prediction results\n",
    "best_predictions = np.asarray([np.argmax(line) for line in predictions])\n",
    "\n",
    "print(accuracy_score(Y_validation, best_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
